{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tRkwba_kTNgo"
      },
      "outputs": [],
      "source": [
        "##  Tokenization\n",
        "##  Para ----> Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dQhBVPwiTndt"
      },
      "outputs": [],
      "source": [
        "corpus = '''  This is first sentence . This is second sentence .  '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Uy3PqzuHTbHQ"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g0Kq37MT8Ce",
        "outputId": "47970424-7f8c-4644-e515-cba5da6cb85b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fpyXP98KTzN7"
      },
      "outputs": [],
      "source": [
        "documents =sent_tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X4lMQWVUQZl",
        "outputId": "6663dc6a-cedb-4f5b-b929-6f4f4f0913a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc17EMBLUVZW",
        "outputId": "eec3fd49-1506-4112-aa36-ff78a72bd69e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  This is first sentence .\n",
            "This is second sentence .\n"
          ]
        }
      ],
      "source": [
        "for sentence in documents:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "N9snAEdHUidq"
      },
      "outputs": [],
      "source": [
        "##  Tokenization\n",
        "##  Paragraph ----> words\n",
        "##  sentence -----> words\n",
        "\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRuDpXBfU0S-",
        "outputId": "0621e767-30db-4fb7-9107-1a913d5ad9cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'first',\n",
              " 'sentence',\n",
              " '.',\n",
              " 'This',\n",
              " 'is',\n",
              " 'second',\n",
              " 'sentence',\n",
              " '.']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5Qt83HJU8he",
        "outputId": "a470a453-0de7-4d7f-c9c2-d761255bdefe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['This', 'is', 'first', 'sentence', '.']\n",
            "['This', 'is', 'second', 'sentence', '.']\n"
          ]
        }
      ],
      "source": [
        "for sentence in documents:\n",
        "    print(word_tokenize(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1QUzSCGVJo3",
        "outputId": "8c4e9cc3-2181-4d1f-8951-4f0150dc8e56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'first',\n",
              " 'sentence',\n",
              " '.',\n",
              " 'This',\n",
              " 'is',\n",
              " 'second',\n",
              " 'sentence',\n",
              " '.']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "wordpunct_tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "v4Om66bnVVei"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vsu8ybGkVfRG",
        "outputId": "02ea5ea3-c10b-44b8-bf89-15208c1bf8ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'first',\n",
              " 'sentence',\n",
              " '.',\n",
              " 'This',\n",
              " 'is',\n",
              " 'second',\n",
              " 'sentence',\n",
              " '.']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = TreebankWordTokenizer()\n",
        "\n",
        "tokenizer.tokenize(corpus)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
